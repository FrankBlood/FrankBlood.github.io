<!doctype html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Embedding,Attention,Character,Residual," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="Note for Papers in ICLR 2017 about NLPInternational Conference on Learning Representations known as ICLR is one of the topest Conference. Because I have being concentrating on the representation of t">
<meta property="og:type" content="article">
<meta property="og:title" content="ICLR_2017_for_NLP">
<meta property="og:url" content="https://frankblood.github.io/2017/01/13/ICLR-2017-for-NLP/index.html">
<meta property="og:site_name" content="Study in IRLAB">
<meta property="og:description" content="Note for Papers in ICLR 2017 about NLPInternational Conference on Learning Representations known as ICLR is one of the topest Conference. Because I have being concentrating on the representation of t">
<meta property="og:image" content="https://frankblood.github.io/2017/01/13/ICLR-2017-for-NLP/character-aware-attention-residual-network.png">
<meta property="og:image" content="https://frankblood.github.io/2017/01/13/ICLR-2017-for-NLP/sentence-representation.png">
<meta property="og:image" content="https://frankblood.github.io/2017/01/13/ICLR-2017-for-NLP/attention-mechanism.png">
<meta property="og:image" content="https://frankblood.github.io/2017/01/13/ICLR-2017-for-NLP/residual-network.png">
<meta property="og:updated_time" content="2017-01-13T03:00:11.918Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ICLR_2017_for_NLP">
<meta name="twitter:description" content="Note for Papers in ICLR 2017 about NLPInternational Conference on Learning Representations known as ICLR is one of the topest Conference. Because I have being concentrating on the representation of t">
<meta name="twitter:image" content="https://frankblood.github.io/2017/01/13/ICLR-2017-for-NLP/character-aware-attention-residual-network.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://frankblood.github.io/2017/01/13/ICLR-2017-for-NLP/"/>





  <title> ICLR_2017_for_NLP | Study in IRLAB </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Study in IRLAB</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <p class="site-subtitle">Embedding, RNN and so on</p>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="st-search-show-outputs">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <form class="site-search-form">
  <input type="text" id="st-search-input" class="st-search-input st-default-search-input" />
</form>

<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install', 'Ceo8xts56UsQv4RPjsSy','2.0.0');
</script>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://frankblood.github.io/2017/01/13/ICLR-2017-for-NLP/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="He Guoxiu">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.png">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Study in IRLAB">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Study in IRLAB" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                ICLR_2017_for_NLP
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-13T10:28:40+08:00">
                2017-01-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Note/" itemprop="url" rel="index">
                    <span itemprop="name">Note</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/01/13/ICLR-2017-for-NLP/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/01/13/ICLR-2017-for-NLP/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><meta http-equiv="content-type" content="text/html; charset=UTF-8"></p>
<h1 id="Note-for-Papers-in-ICLR-2017-about-NLP"><a href="#Note-for-Papers-in-ICLR-2017-about-NLP" class="headerlink" title="Note for Papers in ICLR 2017 about NLP"></a>Note for Papers in ICLR 2017 about NLP</h1><p><strong>International Conference on Learning Representations known as ICLR is one of the topest Conference. Because I have being concentrating on the representation of the text more, I have done a review of the papers in ICLR on NLP.</strong><br><a id="more"></a></p>
<h2 id="1-Representation-of-Character-Word-and-Sentence"><a href="#1-Representation-of-Character-Word-and-Sentence" class="headerlink" title="1. Representation of Character, Word and Sentence"></a>1. Representation of Character, Word and Sentence</h2><p><strong>Representations or Embeddings in many ways</strong></p>
<h3 id="1-1-Character-Aware-Attention-Residual-Network-for-Sentence-Representation"><a href="#1-1-Character-Aware-Attention-Residual-Network-for-Sentence-Representation" class="headerlink" title="1.1 Character-Aware Attention Residual Network for Sentence Representation"></a>1.1 Character-Aware Attention Residual Network for Sentence Representation</h3><p><strong>One way about the sentence embedding by Xin Zheng&#xFF08;Nanyang Technological University, Singapore&#xFF09;, Zhenzhou Wu(SAP)</strong></p>
<ul>
<li>Goal: Classify short and noisy text</li>
<li><p>Problem: </p>
<ul>
<li>Feature sparsity using bag-of-word model, with TFIDF or other weighting schemes</li>
<li>Bag-of-word method has an intrinsic disadvantage that two separate features will be generated for two words with the same root or of different tenses. In other word, the morphology is very important to understand the information of the short document.</li>
<li>Word2vec or Doc2Vec which are distributed word representation miss the word morphology information and word combination information.</li>
</ul>
</li>
<li><p>Backgroud: The quality of document representation here has a great impact on the classification accuracy.</p>
</li>
<li><p>Works of this paper:</p>
<ul>
<li>Take word morphology and word semantic meaning into considerationby using character-aware embedding and word distributed embedding.(This may be the common benefit of the embeddings.)</li>
<li>To obtained a sentence representation matrix: concatenate both character-level and word distributed embedding together and arranging words in order. Sentence representation vector is then derived based on different views from sentence representation matrix to overcome data sparsity problem of short text. At last, a residual network is employed on the sentence embedding to get a consistent and refined sentence representation.(The detials will be shown later.)</li>
</ul>
</li>
<li><p>Details of the model:<br>This paper proposes a character-aware attention residual network to generate sentence representation as the Figure shown.<br><img src="/2017/01/13/ICLR-2017-for-NLP/character-aware-attention-residual-network.png" alt="character-aware-attention-residual-network"></p>
<ol>
<li>A matrix constructed by characters embedding in word is encoded into a vector by convolution network.</li>
<li>Concatenate both character-level embedding and word semantic embedding into a word representation vector.</li>
<li>A sentence is represented by a matrix.</li>
<li>Enrich sentence representation vector by Attention Mechanism: solve the problem that not all the features contribute the same for classification(or other tasks) and target on pertinent parts.</li>
<li>Refine sentence representation vector by Residual network: extracte features from different views consistent.</li>
<li>Obtain the final sentence vector for the classification(or other tasks).</li>
</ol>
</li>
<li><p>More details of the model: </p>
<ul>
<li>Word representation construction: $C$ is vocabulary of characters, $E\in R^{d_c\dot |C|}$ is the character embedding matrix, $d_c$ is the dimensionality of character embedding, $E^w\in R^{d_c\dot n_c}$ is word character-level embedding matrix, $E_i^w=E\dot v_i$ where $v_i$ is a binary column vector that is one row in $E$. Then use convolution network to get the vector $q_c$ which captures the character-level information.(But I still don&#x2019;t know how does the paper solve the problem that the dimentions of the matrix are not same about all words. Maybe some skills known as the padding?) The character-level embedding can only caputure the word morphological features, therefore concatenating the distributed word representative vector as the reflect of the word semantic and syntactic characteristics.</li>
<li>Sentence representation vector construction: shown as below:<br><img src="/2017/01/13/ICLR-2017-for-NLP/sentence-representation.png" alt="sentence-representation"><br>Using different weights for every vector of matirx and attention mechanism to enrich the sentence representation.<ul>
<li>attention mechanism shown as below.<br><img src="/2017/01/13/ICLR-2017-for-NLP/attention-mechanism.png" alt="attention-mechanism"><br>$g(q_i)=Tanh(W_{qh}q_i+b_{qh})$<br>$s_i=\frac{exp(g(q_i))}{\sum_{n_w}^{j=1} exp(g(q_j))}, \hat q_i=s_i q_i$</li>
<li>convolution operations on $Q$ with n-grams.</li>
</ul>
</li>
<li>Residual Network for Refining Sentence Representation: shown as below:<br><img src="/2017/01/13/ICLR-2017-for-NLP/residual-network.png" alt="residual-network"><br>That is one kind of convolution network. But I konw nothing about the residual.-_-|| So let it go.:)</li>
</ul>
</li>
<li><p>Experiments: The model outperforms stat-of-the-art models on a few short-text datasets.</p>
<ul>
<li>Dataset</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">Dataset</th>
<th style="text-align:center">classes</th>
<th style="text-align:center">Train Samples</th>
<th style="text-align:center">Test Samples</th>
<th style="text-align:center">Average Length of text</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Tweet</td>
<td style="text-align:center">5</td>
<td style="text-align:center">28,000</td>
<td style="text-align:center">7,500</td>
<td style="text-align:center">7</td>
</tr>
<tr>
<td style="text-align:center">Question</td>
<td style="text-align:center">5</td>
<td style="text-align:center">2,000</td>
<td style="text-align:center">700</td>
<td style="text-align:center">25</td>
</tr>
<tr>
<td style="text-align:center">AG_news</td>
<td style="text-align:center">5</td>
<td style="text-align:center">120,000</td>
<td style="text-align:center">7,600</td>
<td style="text-align:center">20</td>
</tr>
</tbody>
</table>
<ul>
<li>Other details of the experiment is ignored by me.:)</li>
<li>The result is very good.:)</li>
</ul>
<ul>
<li>High insight:<blockquote>
<ul>
<li>We must explain the word-level representation about the Chinese. And that is important also.</li>
<li>Attention mechanism which focuses on specific part of input could help achieve this goal that not all the words in a sentence contribute the same when predicting the sentence&#x2019;s label</li>
</ul>
</blockquote>
</li>
</ul>
<h1 id="To-be-continued"><a href="#To-be-continued" class="headerlink" title="To be continued."></a>To be continued.</h1><h3 id="1-2-Program-Synthesis-for-Character-Level-Language-Modeling"><a href="#1-2-Program-Synthesis-for-Character-Level-Language-Modeling" class="headerlink" title="1.2 Program Synthesis for Character Level Language Modeling"></a>1.2 Program Synthesis for Character Level Language Modeling</h3>
      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>


    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Embedding/" rel="tag"># Embedding</a>
          
            <a href="/tags/Attention/" rel="tag"># Attention</a>
          
            <a href="/tags/Character/" rel="tag"># Character</a>
          
            <a href="/tags/Residual/" rel="tag"># Residual</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/01/08/Learning-Phrase-Representations-using-RNN-Encoder-Decoder-for-Statistical-Machine-Traslation/" rel="next" title="Learning Phrase Representations<br>using RNN Encoder Decoder for Statistical Machine Traslation">
                <i class="fa fa-chevron-left"></i> Learning Phrase Representations<br>using RNN Encoder Decoder for Statistical Machine Traslation
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/01/16/Introduction-to-TkPro-BrokenDetection/" rel="prev" title="Introduction-to-TkPro-BrokenDetection">
                Introduction-to-TkPro-BrokenDetection <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div class="ds-thread" data-thread-key="2017/01/13/ICLR-2017-for-NLP/"
           data-title="ICLR_2017_for_NLP" data-url="https://frankblood.github.io/2017/01/13/ICLR-2017-for-NLP/">
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.png"
               alt="He Guoxiu" />
          <p class="site-author-name" itemprop="name">He Guoxiu</p>
          <p class="site-description motion-element" itemprop="description">Some notes for interesting papers, tutorials for useful tools, and inspire for life.</p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">11</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">17</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/FrankBlood" target="_blank" title="Github">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  Github
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Note-for-Papers-in-ICLR-2017-about-NLP"><span class="nav-number">1.</span> <span class="nav-text">Note for Papers in ICLR 2017 about NLP</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Representation-of-Character-Word-and-Sentence"><span class="nav-number">1.1.</span> <span class="nav-text">1. Representation of Character, Word and Sentence</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-Character-Aware-Attention-Residual-Network-for-Sentence-Representation"><span class="nav-number">1.1.1.</span> <span class="nav-text">1.1 Character-Aware Attention Residual Network for Sentence Representation</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#To-be-continued"><span class="nav-number">2.</span> <span class="nav-text">To be continued.</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-Program-Synthesis-for-Character-Level-Language-Modeling"><span class="nav-number">2.0.1.</span> <span class="nav-text">1.2 Program Synthesis for Character Level Language Modeling</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">He Guoxiu</span>
</div>



        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"frankblood"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    
    <script src="/lib/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  










  
  

  

  

  

  


</body>
</html>
